{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import data_cleaning as dc\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_person = pd.read_json(r'../week_sleep_data.json', orient='records', lines=True)\n",
    "st_df = pd.read_json(r\"../datasets/streamlit_sleep_data.json\", orient='records', lines=True)\n",
    "person_1 = pd.read_json(r'../datasets/bangnon_33.json', orient='records', lines=True)\n",
    "person_2 = pd.read_json(r'../datasets/bertablabla.json', lines=True)\n",
    "person_3 = pd.read_json(r'../datasets/boom_90.json', lines=True)\n",
    "person_4 = pd.read_json(r'../datasets/westbrook_30days.json', lines=True)\n",
    "\n",
    "\n",
    "# test data\n",
    "syahid_21 = pd.read_json(r'../datasets/sleep_data_til_21_syahid.json', orient='records', lines=True)\n",
    "liza_21 = pd.read_json(r'../datasets/sleep_data_til_21_liza.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 15 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   dailySleepDTO                        15 non-null     object \n",
      " 1   sleepMovement                        14 non-null     object \n",
      " 2   remSleepData                         14 non-null     float64\n",
      " 3   sleepLevels                          14 non-null     object \n",
      " 4   sleepRestlessMoments                 14 non-null     object \n",
      " 5   restlessMomentsCount                 14 non-null     float64\n",
      " 6   wellnessEpochRespirationDataDTOList  13 non-null     object \n",
      " 7   sleepHeartRate                       13 non-null     object \n",
      " 8   sleepStress                          13 non-null     object \n",
      " 9   sleepBodyBattery                     13 non-null     object \n",
      " 10  hrvData                              14 non-null     object \n",
      " 11  avgOvernightHrv                      14 non-null     float64\n",
      " 12  hrvStatus                            14 non-null     object \n",
      " 13  bodyBatteryChange                    13 non-null     float64\n",
      " 14  restingHeartRate                     14 non-null     float64\n",
      "dtypes: float64(5), object(10)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "liza_21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_untracked_nights(df):\n",
    "    \"\"\"\n",
    "    Delete the untracked nights by using the restlessMomentsCount.\n",
    "    This is because restless moments are only registered in the watch when sleep is detected.\n",
    "    The subset was -restlessMomentsCount-.\n",
    "    \"\"\"\n",
    "    #df['sleepMovement'] = df['sleepMovement'].replace('[]', np.nan)\n",
    "    return df.dropna(subset=[\"sleepMovement\", \"restlessMomentsCount\"]).reset_index(drop=True) # reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "def convert_timestamps(df, timestamp_column, time_offset_hours=0):\n",
    "    \"\"\"\n",
    "    Function that converts timestamps in a dataframe to a timezone-aware datetime format.\n",
    "    \"\"\" \n",
    "    # Convert timestamp column to datetime\n",
    "    df[timestamp_column] = pd.to_datetime(df[timestamp_column], unit='ms')\n",
    "\n",
    "    # Convert GMT to local time by adding the specified number of hours\n",
    "    #local_time_column = \"startLocal\"\n",
    "    df[timestamp_column] = df[timestamp_column] + timedelta(hours=time_offset_hours)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_columns = [\"sleepRestlessMoments\", \"hrvData\", \"sleepStress\", \"sleepBodyBattery\", \n",
    "                      \"sleepHeartRate\", \"wellnessEpochRespirationDataDTOList\", \"sleepLevels\"]\n",
    "\n",
    "def extract_value(df):\n",
    "    interested_columns = [\"sleepRestlessMoments\", \"hrvData\", \"sleepStress\", \"sleepBodyBattery\", \n",
    "                      \"sleepHeartRate\", \"wellnessEpochRespirationDataDTOList\", \"sleepLevels\"]\n",
    "    dfs= []\n",
    "    for column in interested_columns:\n",
    "        if column == 'sleepLevels':\n",
    "            # column with startGMT, endGMT and activityLevel\n",
    "            # 3 columns in total\n",
    "            df1 = pd.concat([pd.json_normalize(item) for item in df[column]])\n",
    "            # change the date from string to datetime\n",
    "            df1['startGMT'] = pd.to_datetime(df1['startGMT'])\n",
    "            # add 1 hour timedelta, to get local time\n",
    "            df1['startGMT'] += timedelta(hours=1)\n",
    "            df1.drop(\"endGMT\", axis='columns', inplace=True)\n",
    "            # we need to rename the column activityLevel to sleepLevel_value\n",
    "            df1.rename(columns={'activityLevel': 'sleepLevel_value'}, inplace=True)\n",
    "        elif column == 'wellnessEpochRespirationDataDTOList':\n",
    "            # 2 columns startTimeGMT and value\n",
    "            # column start with startTimeGMT\n",
    "            df2 = pd.concat([pd.json_normalize(item) for item in df[column]])\n",
    "            df2.rename(columns={'startTimeGMT': 'startGMT', \n",
    "                                'value': f'{column}_value'}, inplace=True)\n",
    "            convert_timestamps(df2, 'startGMT', 1)\n",
    "            ### we need to rename the column value to f\"{column_name}_value\"\n",
    "        else:\n",
    "            # 2 columns, startGMT and value\n",
    "            df3 = pd.concat([pd.json_normalize(item) for item in df[column]])\n",
    "            convert_timestamps(df3, 'startGMT', 1)\n",
    "            ### we need to rename the column value to f\"{column_name}_value\"\n",
    "            df3.rename(columns={'value': f'{column}_value'}, inplace=True)\n",
    "            dfs.append(df3)\n",
    "\n",
    "    return df1, df2, dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_extracted_dataframes(main_df):\n",
    "    # Extract the first two DataFrames and the list of DataFrames using the extract_value function\n",
    "    df1 = extract_value(main_df)[0].set_index('startGMT')\n",
    "    df2 = extract_value(main_df)[1].set_index('startGMT')\n",
    "    df_list = extract_value(main_df)[2]\n",
    " \n",
    "    # Merge df1 and df2 first. They are merged on their indices.\n",
    "    merged_df = df1.merge(df2, left_index=True, right_index=True, how='outer')\n",
    " \n",
    "    # Iteratively merge each DataFrame in df_list with merged_df\n",
    "    for df in df_list:\n",
    "        df.set_index('startGMT', inplace=True)  # Set 'startGMT' as the index for each DataFrame in df_list\n",
    "        merged_df = merged_df.merge(df, left_index=True, right_index=True, how='outer')  # Adjust the merge type as necessary\n",
    " \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns_to_interpolate(columns_to_rename):\n",
    "    columns_to_interpolate = []\n",
    "    for string in columns_to_rename:\n",
    "        columns_to_interpolate.append(f\"{string}_value\")\n",
    "    columns_to_interpolate.append('respirationValue')\n",
    "    return columns_to_interpolate\n",
    " \n",
    "def interpolate_dataframe(merged_df, columns_to_interpolate):\n",
    "    interpolated_df = merged_df.copy()\n",
    "    for column in columns_to_interpolate:\n",
    "        if column in ['sleepLevel_value', 'sleepRestlessMoments_value']:\n",
    "            # Use forward fill for these columns\n",
    "            interpolated_df[column] = interpolated_df[column].ffill() # same as interpolation (pad method)\n",
    "            interpolated_df[column] = interpolated_df[column].bfill() # backward fill the NaN values\n",
    "        else:\n",
    "            # Use time interpolation for other columns\n",
    "            interpolated_df[column] = interpolated_df[column].interpolate(method='time') # interpolation (time)\n",
    "            interpolated_df[column] = interpolated_df[column].bfill() # backward fill the NaN values\n",
    "    return interpolated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(original_df):\n",
    "    # Step 1: Delete untracked nights\n",
    "    cleaned_df = delete_untracked_nights(original_df)\n",
    "\n",
    "    # Extrahieren der Schlafstart- und -endzeiten in einem neuen DataFrame\n",
    "    df_temp = pd.json_normalize(cleaned_df['dailySleepDTO'])[['sleepStartTimestampLocal', 'sleepEndTimestampLocal']]\n",
    "    df_temp['sleepStartTimestampLocal'] = pd.to_datetime(df_temp['sleepStartTimestampLocal'], unit='ms')\n",
    "    df_temp['sleepEndTimestampLocal'] = pd.to_datetime(df_temp['sleepEndTimestampLocal'], unit='ms')\n",
    "\n",
    "    # Step 2: Merge the extracted DataFrames\n",
    "    merged_df = merge_extracted_dataframes(cleaned_df)\n",
    "\n",
    "    # Step 3: Generate column names for interpolation\n",
    "    columns_to_rename = [\"sleepRestlessMoments\", \"hrvData\", \"sleepStress\", \"sleepBodyBattery\",\n",
    "                         \"sleepHeartRate\", \"sleepLevel\"]\n",
    "    columns_to_interpolate = generate_columns_to_interpolate(columns_to_rename)\n",
    "\n",
    "    # Step 4: Resample and interpolate\n",
    "    resampled_df = merged_df.resample('T').mean()  # Diskutieren, ob eine oder zwei Minuten\n",
    "    final_processed_df = interpolate_dataframe(resampled_df, columns_to_interpolate)\n",
    "\n",
    "    # Step 5: Split the night separately\n",
    "    night_dfs = {}\n",
    "    for index, row in df_temp.iterrows():\n",
    "        start = row['sleepStartTimestampLocal']\n",
    "        end = row['sleepEndTimestampLocal']\n",
    "        filtered_df = final_processed_df[start:end]\n",
    "        night_dfs[index] = filtered_df\n",
    "\n",
    "    return night_dfs  # Return a dictionary of night DataFrames\n",
    "\n",
    "nights_dataframes = main(liza_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 12, 8)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nights_dataframes[0].index[-1].date() # time to wake up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2023-12-08\n",
      "1 2023-12-09\n",
      "2 2023-12-10\n",
      "3 2023-12-11\n",
      "4 2023-12-12\n",
      "5 2023-12-14\n",
      "6 2023-12-15\n",
      "7 2023-12-16\n",
      "8 2023-12-17\n",
      "9 2023-12-18\n",
      "10 2023-12-19\n",
      "11 2023-12-20\n",
      "12 2023-12-21\n"
     ]
    }
   ],
   "source": [
    "for night in nights_dataframes.items():\n",
    "    print(night[0], night[1].index[-1].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(original_df):\n",
    "#     # Step 1: Delete untracked nights\n",
    "#     cleaned_df = delete_untracked_nights(original_df)\n",
    " \n",
    "#     # Step2 : Merge the extracted DataFrames\n",
    "#     merged_df = merge_extracted_dataframes(cleaned_df)\n",
    " \n",
    "#     # Step 3: Generate column names for interpolation\n",
    "#     columns_to_rename = [\"sleepRestlessMoments\", \"hrvData\", \"sleepStress\", \"sleepBodyBattery\",\n",
    "#                          \"sleepHeartRate\", \"sleepLevel\"]\n",
    "#     columns_to_interpolate = generate_columns_to_interpolate(columns_to_rename)\n",
    "\n",
    "#     #step 3.5\n",
    "#     # split the night separately\n",
    "\n",
    "#     # Step 4: Do the resample based on time in one minute interval (discuss whether to use one or 2 minutes)\n",
    "#     #merged_df = merged_df.resample('T').mean()\n",
    " \n",
    "#     # Step 5: Perform the interpolation\n",
    "#     final_df = interpolate_dataframe(merged_df, columns_to_interpolate)\n",
    " \n",
    "#     return final_df # return a night dict\n",
    " \n",
    "# # Use the main function with your original DataFrame:\n",
    "# final_processed_df = main(liza_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dig_health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
