{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import draft.data_cleaning as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_0 = pd.read_json(r'datasets/december/liza.json', orient='records', lines=True) # liza\n",
    "person_1 = pd.read_json(r'datasets/december/sleep_data_Adham.json', lines=True) # adham\n",
    "person_2 = pd.read_json(r'datasets/december/sleep_data_Miriam.json', lines=True) # miriam\n",
    "person_3 = pd.read_json(r'datasets/december/sleep_data_Syahid.json', lines=True) # syahid\n",
    "person_4 = pd.read_json(r'datasets/december/sleep_data_Florian.json', lines=True) # florian\n",
    "person_5 = pd.read_json(r'datasets/december/sleep_data_Shado.json', lines=True) # shado\n",
    "person_6 = pd.read_json(r'datasets/december/sleep_data_Alina.json', lines=True) # alina\n",
    "\n",
    "# labels dataframe from excel\n",
    "labels_df = pd.read_excel(r'datasets\\sleep_data.xlsx', sheet_name=None) # dict of all label|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = [person_0, person_1, person_2, person_3, person_4, person_5, person_6]\n",
    "\n",
    "for num, df in enumerate(people_df):\n",
    "    df.insert(0, \"temp_id\", num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[embeddings + static data] + label --> RF (Leute mit Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_data(df):\n",
    "    # Extract temp_id\n",
    "    temp_id = df['temp_id']\n",
    "\n",
    "    # static data from dailySleepDTO json\n",
    "    sleepDTO_df = pd.json_normalize(df['dailySleepDTO'])\n",
    "\n",
    "    cols_to_keep = ['id', 'calendarDate', 'sleepTimeSeconds', 'sleepStartTimestampLocal',\n",
    "       'sleepEndTimestampLocal', 'deepSleepSeconds', 'lightSleepSeconds',\n",
    "       'remSleepSeconds', 'awakeSleepSeconds', 'averageRespirationValue',\n",
    "       'lowestRespirationValue', 'highestRespirationValue', 'awakeCount',\n",
    "       'avgSleepStress', 'ageGroup', 'sleepVersion',\n",
    "       'sleepScores.totalDuration.qualifierKey',\n",
    "       'sleepScores.stress.qualifierKey',\n",
    "       'sleepScores.awakeCount.qualifierKey', 'sleepScores.overall.value',\n",
    "       'sleepScores.remPercentage.value',\n",
    "       'sleepScores.remPercentage.idealStartInSeconds',\n",
    "       'sleepScores.remPercentage.idealEndInSeconds',\n",
    "       'sleepScores.restlessness.qualifierKey',\n",
    "       'sleepScores.lightPercentage.value',\n",
    "       'sleepScores.lightPercentage.idealStartInSeconds',\n",
    "       'sleepScores.lightPercentage.idealEndInSeconds',\n",
    "       'sleepScores.deepPercentage.value',\n",
    "       'sleepScores.deepPercentage.idealStartInSeconds',\n",
    "       'sleepScores.deepPercentage.idealEndInSeconds']\n",
    "    \n",
    "    sleepDTO_df = sleepDTO_df[cols_to_keep]\n",
    "\n",
    "    # Add temp_id to the sleepDTO_df\n",
    "    sleepDTO_df['temp_id'] = temp_id \n",
    "\n",
    "    # change the time format\n",
    "    sleepDTO_df['sleepStartTimestampLocal'] = pd.to_datetime(sleepDTO_df['sleepStartTimestampLocal'], unit='ms')\n",
    "    sleepDTO_df['sleepEndTimestampLocal'] = pd.to_datetime(sleepDTO_df['sleepEndTimestampLocal'], unit='ms')\n",
    "\n",
    "    return sleepDTO_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_static_data(df):\n",
    "    # Process the sleepDTO data\n",
    "    sleepDTO = get_static_data(df)\n",
    "\n",
    "    # Extract the required static values from the original DataFrame\n",
    "    cols = ['temp_id', 'remSleepData', 'restlessMomentsCount', 'avgOvernightHrv', 'restingHeartRate']\n",
    "    static_values = df[cols]\n",
    "\n",
    "    # Set 'temp_id' as the index for both DataFrames\n",
    "    static_values.set_index('temp_id', inplace=True)\n",
    "    sleepDTO.set_index('temp_id', inplace=True)\n",
    "\n",
    "    # Concatenate static_values and sleepDTO horizontally\n",
    "    combined_data = pd.concat([sleepDTO, static_values], axis=1)\n",
    "\n",
    "    # Reset the index if you want 'temp_id' back as a column\n",
    "    combined_data.reset_index(inplace=True)\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        if col.endswith(\"qualifierKey\"):\n",
    "            new_name = col.replace(\"qualifierKey\", \"value\")\n",
    "            dataframe[new_name] = dataframe[col].apply(dc.convert_num)\n",
    "            dataframe.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sleepDTO --> drop irrelavnt columns --> change qualifier key to integer\n",
    "static values \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dict = {0: 'Liza', 1: 'Adham', 2: 'Miriam', 3: 'Syahid', 4: 'Florian', 5: 'Shado', 6: 'Alina'} # excel\n",
    "\n",
    "persons_static_data = {\n",
    "    0 : person_0,\n",
    "    1 : person_1,\n",
    "    2 : person_2,\n",
    "    3 : person_3,\n",
    "    4 : person_4,\n",
    "    5 : person_5,\n",
    "    6 : person_6\n",
    "}\n",
    "\n",
    "def process_all_people(persons_static_data): # we put persons_data as the argument\n",
    "    processed_people = {}\n",
    "\n",
    "    for person_id, person_df in persons_static_data.items():\n",
    "        # Clean the data for each person\n",
    "        cleaned_df = dc.delete_untracked_nights(person_df)\n",
    "\n",
    "        # Combine the static data\n",
    "        combined_df = combine_static_data(cleaned_df)\n",
    "\n",
    "        # Process the DataFrame to change 'qualifierKey' to numerical value\n",
    "        final_processed_df = process_dataframe(combined_df)\n",
    "\n",
    "        # Load the embeddings DataFrame from a pickle file according to person id\n",
    "        embeddings_file_name = f\"datasets/embeddings_100/embeddings_{person_id}.pkl\"\n",
    "        embeddings_df = pd.read_pickle(embeddings_file_name)\n",
    "\n",
    "        # combine the static and the embeddings\n",
    "        combined_df_with_embeddings = pd.concat([final_processed_df, embeddings_df], axis=1)\n",
    "\n",
    "        # Store the processed DataFrame in the dictionary with the same person_id\n",
    "        processed_people[person_id] = combined_df_with_embeddings\n",
    "\n",
    "    return processed_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = process_all_people(persons_static_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_id</th>\n",
       "      <th>id</th>\n",
       "      <th>calendarDate</th>\n",
       "      <th>sleepTimeSeconds</th>\n",
       "      <th>sleepStartTimestampLocal</th>\n",
       "      <th>sleepEndTimestampLocal</th>\n",
       "      <th>deepSleepSeconds</th>\n",
       "      <th>lightSleepSeconds</th>\n",
       "      <th>remSleepSeconds</th>\n",
       "      <th>awakeSleepSeconds</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_90</th>\n",
       "      <th>embedding_91</th>\n",
       "      <th>embedding_92</th>\n",
       "      <th>embedding_93</th>\n",
       "      <th>embedding_94</th>\n",
       "      <th>embedding_95</th>\n",
       "      <th>embedding_96</th>\n",
       "      <th>embedding_97</th>\n",
       "      <th>embedding_98</th>\n",
       "      <th>embedding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1701986940000</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>36780</td>\n",
       "      <td>2023-12-07 23:09:00</td>\n",
       "      <td>2023-12-08 09:34:00</td>\n",
       "      <td>3780</td>\n",
       "      <td>27000</td>\n",
       "      <td>6000</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.294890</td>\n",
       "      <td>1.599485</td>\n",
       "      <td>1.008841</td>\n",
       "      <td>1.276859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1702078860000</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>29940</td>\n",
       "      <td>2023-12-09 00:41:00</td>\n",
       "      <td>2023-12-09 09:42:00</td>\n",
       "      <td>3240</td>\n",
       "      <td>24480</td>\n",
       "      <td>2220</td>\n",
       "      <td>2520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.403386</td>\n",
       "      <td>2.422224</td>\n",
       "      <td>1.581123</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350698</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1702171920000</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>25080</td>\n",
       "      <td>2023-12-10 02:32:00</td>\n",
       "      <td>2023-12-10 09:39:00</td>\n",
       "      <td>2040</td>\n",
       "      <td>17580</td>\n",
       "      <td>5460</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.174797</td>\n",
       "      <td>2.238895</td>\n",
       "      <td>2.448936</td>\n",
       "      <td>0.778737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1702254240000</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>21420</td>\n",
       "      <td>2023-12-11 01:24:00</td>\n",
       "      <td>2023-12-11 07:22:00</td>\n",
       "      <td>3720</td>\n",
       "      <td>15000</td>\n",
       "      <td>2700</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544954</td>\n",
       "      <td>2.681309</td>\n",
       "      <td>1.326715</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.362635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1702340700000</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>31080</td>\n",
       "      <td>2023-12-12 01:25:00</td>\n",
       "      <td>2023-12-12 10:04:00</td>\n",
       "      <td>6540</td>\n",
       "      <td>17520</td>\n",
       "      <td>7020</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630449</td>\n",
       "      <td>1.376675</td>\n",
       "      <td>2.312008</td>\n",
       "      <td>1.645187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1702510140000</td>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>23880</td>\n",
       "      <td>2023-12-14 00:29:00</td>\n",
       "      <td>2023-12-14 07:21:00</td>\n",
       "      <td>5280</td>\n",
       "      <td>15600</td>\n",
       "      <td>3000</td>\n",
       "      <td>840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.339422</td>\n",
       "      <td>2.192270</td>\n",
       "      <td>1.335280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1702596000000</td>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>32100</td>\n",
       "      <td>2023-12-15 00:20:00</td>\n",
       "      <td>2023-12-15 09:27:00</td>\n",
       "      <td>3540</td>\n",
       "      <td>23520</td>\n",
       "      <td>5040</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.175953</td>\n",
       "      <td>0.543134</td>\n",
       "      <td>2.698443</td>\n",
       "      <td>0.960822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1702680600000</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>38040</td>\n",
       "      <td>2023-12-15 23:50:00</td>\n",
       "      <td>2023-12-16 10:56:00</td>\n",
       "      <td>4500</td>\n",
       "      <td>22380</td>\n",
       "      <td>11160</td>\n",
       "      <td>1920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734908</td>\n",
       "      <td>0.199487</td>\n",
       "      <td>1.495331</td>\n",
       "      <td>0.930846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1702777020000</td>\n",
       "      <td>2023-12-17</td>\n",
       "      <td>25260</td>\n",
       "      <td>2023-12-17 02:37:00</td>\n",
       "      <td>2023-12-17 09:44:00</td>\n",
       "      <td>3780</td>\n",
       "      <td>18000</td>\n",
       "      <td>3480</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878956</td>\n",
       "      <td>1.722102</td>\n",
       "      <td>2.497085</td>\n",
       "      <td>0.465217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1702858680000</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>30176</td>\n",
       "      <td>2023-12-18 01:18:00</td>\n",
       "      <td>2023-12-18 09:59:56</td>\n",
       "      <td>3000</td>\n",
       "      <td>22740</td>\n",
       "      <td>4380</td>\n",
       "      <td>1140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541869</td>\n",
       "      <td>2.074739</td>\n",
       "      <td>2.222410</td>\n",
       "      <td>1.690510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1702941960000</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>23040</td>\n",
       "      <td>2023-12-19 00:26:00</td>\n",
       "      <td>2023-12-19 07:01:00</td>\n",
       "      <td>4620</td>\n",
       "      <td>12420</td>\n",
       "      <td>6000</td>\n",
       "      <td>660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933188</td>\n",
       "      <td>2.404598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1703026260000</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>30900</td>\n",
       "      <td>2023-12-19 23:51:00</td>\n",
       "      <td>2023-12-20 08:51:00</td>\n",
       "      <td>4560</td>\n",
       "      <td>19380</td>\n",
       "      <td>6960</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.054594</td>\n",
       "      <td>1.676670</td>\n",
       "      <td>2.072740</td>\n",
       "      <td>0.579976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1703118300000</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>25140</td>\n",
       "      <td>2023-12-21 01:25:00</td>\n",
       "      <td>2023-12-21 08:41:00</td>\n",
       "      <td>2700</td>\n",
       "      <td>19740</td>\n",
       "      <td>2700</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790034</td>\n",
       "      <td>2.078346</td>\n",
       "      <td>2.397567</td>\n",
       "      <td>0.278920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1703205000000</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>24000</td>\n",
       "      <td>2023-12-22 01:30:00</td>\n",
       "      <td>2023-12-22 08:24:00</td>\n",
       "      <td>4380</td>\n",
       "      <td>14100</td>\n",
       "      <td>5520</td>\n",
       "      <td>840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398924</td>\n",
       "      <td>1.874395</td>\n",
       "      <td>1.983694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1703379480000</td>\n",
       "      <td>2023-12-24</td>\n",
       "      <td>32820</td>\n",
       "      <td>2023-12-24 01:58:00</td>\n",
       "      <td>2023-12-24 11:10:00</td>\n",
       "      <td>4380</td>\n",
       "      <td>22200</td>\n",
       "      <td>6240</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400911</td>\n",
       "      <td>1.306499</td>\n",
       "      <td>1.665031</td>\n",
       "      <td>0.522927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp_id             id calendarDate  sleepTimeSeconds  \\\n",
       "0         0  1701986940000   2023-12-08             36780   \n",
       "1         0  1702078860000   2023-12-09             29940   \n",
       "2         0  1702171920000   2023-12-10             25080   \n",
       "3         0  1702254240000   2023-12-11             21420   \n",
       "4         0  1702340700000   2023-12-12             31080   \n",
       "5         0  1702510140000   2023-12-14             23880   \n",
       "6         0  1702596000000   2023-12-15             32100   \n",
       "7         0  1702680600000   2023-12-16             38040   \n",
       "8         0  1702777020000   2023-12-17             25260   \n",
       "9         0  1702858680000   2023-12-18             30176   \n",
       "10        0  1702941960000   2023-12-19             23040   \n",
       "11        0  1703026260000   2023-12-20             30900   \n",
       "12        0  1703118300000   2023-12-21             25140   \n",
       "13        0  1703205000000   2023-12-22             24000   \n",
       "14        0  1703379480000   2023-12-24             32820   \n",
       "\n",
       "   sleepStartTimestampLocal sleepEndTimestampLocal  deepSleepSeconds  \\\n",
       "0       2023-12-07 23:09:00    2023-12-08 09:34:00              3780   \n",
       "1       2023-12-09 00:41:00    2023-12-09 09:42:00              3240   \n",
       "2       2023-12-10 02:32:00    2023-12-10 09:39:00              2040   \n",
       "3       2023-12-11 01:24:00    2023-12-11 07:22:00              3720   \n",
       "4       2023-12-12 01:25:00    2023-12-12 10:04:00              6540   \n",
       "5       2023-12-14 00:29:00    2023-12-14 07:21:00              5280   \n",
       "6       2023-12-15 00:20:00    2023-12-15 09:27:00              3540   \n",
       "7       2023-12-15 23:50:00    2023-12-16 10:56:00              4500   \n",
       "8       2023-12-17 02:37:00    2023-12-17 09:44:00              3780   \n",
       "9       2023-12-18 01:18:00    2023-12-18 09:59:56              3000   \n",
       "10      2023-12-19 00:26:00    2023-12-19 07:01:00              4620   \n",
       "11      2023-12-19 23:51:00    2023-12-20 08:51:00              4560   \n",
       "12      2023-12-21 01:25:00    2023-12-21 08:41:00              2700   \n",
       "13      2023-12-22 01:30:00    2023-12-22 08:24:00              4380   \n",
       "14      2023-12-24 01:58:00    2023-12-24 11:10:00              4380   \n",
       "\n",
       "    lightSleepSeconds  remSleepSeconds  awakeSleepSeconds  ...  embedding_90  \\\n",
       "0               27000             6000                720  ...           0.0   \n",
       "1               24480             2220               2520  ...           0.0   \n",
       "2               17580             5460                540  ...           0.0   \n",
       "3               15000             2700                 60  ...           0.0   \n",
       "4               17520             7020                 60  ...           0.0   \n",
       "5               15600             3000                840  ...           0.0   \n",
       "6               23520             5040                720  ...           0.0   \n",
       "7               22380            11160               1920  ...           0.0   \n",
       "8               18000             3480                360  ...           0.0   \n",
       "9               22740             4380               1140  ...           0.0   \n",
       "10              12420             6000                660  ...           0.0   \n",
       "11              19380             6960               1500  ...           0.0   \n",
       "12              19740             2700               1020  ...           0.0   \n",
       "13              14100             5520                840  ...           0.0   \n",
       "14              22200             6240                300  ...           0.0   \n",
       "\n",
       "    embedding_91  embedding_92  embedding_93  embedding_94 embedding_95  \\\n",
       "0       1.294890      1.599485      1.008841      1.276859     0.000000   \n",
       "1       2.403386      2.422224      1.581123      0.029759     0.000000   \n",
       "2       1.174797      2.238895      2.448936      0.778737     0.000000   \n",
       "3       0.544954      2.681309      1.326715      0.034641     0.362635   \n",
       "4       0.630449      1.376675      2.312008      1.645187     0.000000   \n",
       "5       1.339422      2.192270      1.335280      0.000000     0.549342   \n",
       "6       1.175953      0.543134      2.698443      0.960822     0.000000   \n",
       "7       0.734908      0.199487      1.495331      0.930846     0.000000   \n",
       "8       0.878956      1.722102      2.497085      0.465217     0.000000   \n",
       "9       0.541869      2.074739      2.222410      1.690510     0.000000   \n",
       "10      0.000000      0.933188      2.404598      0.000000     0.889326   \n",
       "11      1.054594      1.676670      2.072740      0.579976     0.000000   \n",
       "12      1.790034      2.078346      2.397567      0.278920     0.000000   \n",
       "13      0.398924      1.874395      1.983694      0.000000     0.000000   \n",
       "14      1.400911      1.306499      1.665031      0.522927     0.000000   \n",
       "\n",
       "    embedding_96  embedding_97  embedding_98  embedding_99  \n",
       "0            0.0      0.000000      0.131409           0.0  \n",
       "1            0.0      0.000000      0.350698           0.0  \n",
       "2            0.0      0.000000      0.000000           0.0  \n",
       "3            0.0      0.000000      0.000000           0.0  \n",
       "4            0.0      0.000000      0.000000           0.0  \n",
       "5            0.0      0.455504      0.000000           0.0  \n",
       "6            0.0      0.000000      0.000000           0.0  \n",
       "7            0.0      0.000000      0.000000           0.0  \n",
       "8            0.0      0.321693      0.000000           0.0  \n",
       "9            0.0      0.090637      0.000000           0.0  \n",
       "10           0.0      0.111165      0.000000           0.0  \n",
       "11           0.0      0.000000      0.000000           0.0  \n",
       "12           0.0      0.000000      0.000000           0.0  \n",
       "13           0.0      0.159445      0.000000           0.0  \n",
       "14           0.0      0.000000      0.000000           0.0  \n",
       "\n",
       "[15 rows x 135 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[0] # data from liza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_labels(persons_data, labels_df, people_dict):\n",
    "    merged_data = {}\n",
    "\n",
    "    for person_id, person_df in persons_data.items():\n",
    "        # Check if 'calendarDate' exists in person_df\n",
    "        if 'calendarDate' not in person_df.columns:\n",
    "            print(f\"'calendarDate' column not found in person data for {person_id}\")\n",
    "            continue\n",
    "\n",
    "        # Get the label DataFrame for the current person\n",
    "        person_label_df = labels_df[people_dict[person_id]]\n",
    "\n",
    "        # Ensure the date columns are in the same format\n",
    "        person_df['calendarDate'] = pd.to_datetime(person_df['calendarDate'])\n",
    "        person_label_df['Datum'] = pd.to_datetime(person_label_df['Datum'])\n",
    "\n",
    "        # Merge the person's data with their labels on the date\n",
    "        merged_df = pd.merge(person_df, person_label_df, left_on='calendarDate', right_on='Datum')\n",
    "\n",
    "        # Store the merged DataFrame in the dictionary with the same person_id\n",
    "        merged_data[person_id] = merged_df\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "# Example usage\n",
    "merged_people_data = merge_with_labels(all_df, labels_df, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# person 0 --> 4 NaN entries --> test label\n",
    "# person 4 --> 8 NaN entries --> 4 columns can subtitute as '3'. Remaining is test label.\n",
    "# person 6 --> 2 NaN entriies --> can subtitute as '3' (wach, konzentriert)\n",
    "\n",
    "merged_people_data[6].isna().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_id</th>\n",
       "      <th>id</th>\n",
       "      <th>calendarDate</th>\n",
       "      <th>sleepTimeSeconds</th>\n",
       "      <th>sleepStartTimestampLocal</th>\n",
       "      <th>sleepEndTimestampLocal</th>\n",
       "      <th>deepSleepSeconds</th>\n",
       "      <th>lightSleepSeconds</th>\n",
       "      <th>remSleepSeconds</th>\n",
       "      <th>awakeSleepSeconds</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_99</th>\n",
       "      <th>Datum</th>\n",
       "      <th>ausgeschlafen</th>\n",
       "      <th>motivation</th>\n",
       "      <th>konzentriert</th>\n",
       "      <th>Wach</th>\n",
       "      <th>Test_zeit</th>\n",
       "      <th>Test_anzahl</th>\n",
       "      <th>prozent_zeit_rang</th>\n",
       "      <th>prozent_anzahl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1701988440000</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>22800</td>\n",
       "      <td>2023-12-07 23:34:00</td>\n",
       "      <td>2023-12-08 06:21:00</td>\n",
       "      <td>2640</td>\n",
       "      <td>16980</td>\n",
       "      <td>3180</td>\n",
       "      <td>1620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1702067940000</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>35460</td>\n",
       "      <td>2023-12-08 21:39:00</td>\n",
       "      <td>2023-12-09 09:08:00</td>\n",
       "      <td>4620</td>\n",
       "      <td>23580</td>\n",
       "      <td>7260</td>\n",
       "      <td>5880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1702169940000</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>26220</td>\n",
       "      <td>2023-12-10 01:59:00</td>\n",
       "      <td>2023-12-10 09:29:00</td>\n",
       "      <td>2820</td>\n",
       "      <td>18300</td>\n",
       "      <td>5100</td>\n",
       "      <td>780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60.00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1702246860000</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>24780</td>\n",
       "      <td>2023-12-10 23:21:00</td>\n",
       "      <td>2023-12-11 06:16:00</td>\n",
       "      <td>3420</td>\n",
       "      <td>14520</td>\n",
       "      <td>6840</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>61.33</td>\n",
       "      <td>93.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1702334760000</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>23460</td>\n",
       "      <td>2023-12-11 23:46:00</td>\n",
       "      <td>2023-12-12 06:45:00</td>\n",
       "      <td>5040</td>\n",
       "      <td>14100</td>\n",
       "      <td>4320</td>\n",
       "      <td>1680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>60.00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1702421040000</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>23760</td>\n",
       "      <td>2023-12-12 23:44:00</td>\n",
       "      <td>2023-12-13 06:30:00</td>\n",
       "      <td>2460</td>\n",
       "      <td>15360</td>\n",
       "      <td>5940</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>63.67</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1702506960000</td>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>22740</td>\n",
       "      <td>2023-12-13 23:36:00</td>\n",
       "      <td>2023-12-14 06:32:00</td>\n",
       "      <td>3120</td>\n",
       "      <td>14040</td>\n",
       "      <td>5580</td>\n",
       "      <td>2220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>51.67</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1702677060000</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>37140</td>\n",
       "      <td>2023-12-15 22:51:00</td>\n",
       "      <td>2023-12-16 09:36:00</td>\n",
       "      <td>7680</td>\n",
       "      <td>17940</td>\n",
       "      <td>11520</td>\n",
       "      <td>1560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>51.67</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1702772280000</td>\n",
       "      <td>2023-12-17</td>\n",
       "      <td>28920</td>\n",
       "      <td>2023-12-17 01:18:00</td>\n",
       "      <td>2023-12-17 09:40:00</td>\n",
       "      <td>3960</td>\n",
       "      <td>19620</td>\n",
       "      <td>5340</td>\n",
       "      <td>1200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>55.67</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1702853220000</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>23460</td>\n",
       "      <td>2023-12-17 23:47:00</td>\n",
       "      <td>2023-12-18 06:24:00</td>\n",
       "      <td>5940</td>\n",
       "      <td>14100</td>\n",
       "      <td>3420</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>61.33</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>1703026440000</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>23397</td>\n",
       "      <td>2023-12-19 23:54:00</td>\n",
       "      <td>2023-12-20 06:27:57</td>\n",
       "      <td>3360</td>\n",
       "      <td>17040</td>\n",
       "      <td>2940</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>68.67</td>\n",
       "      <td>93.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>1703112840000</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>27180</td>\n",
       "      <td>2023-12-20 23:54:00</td>\n",
       "      <td>2023-12-21 07:33:00</td>\n",
       "      <td>4140</td>\n",
       "      <td>17820</td>\n",
       "      <td>5220</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp_id             id calendarDate  sleepTimeSeconds  \\\n",
       "0         4  1701988440000   2023-12-08             22800   \n",
       "1         4  1702067940000   2023-12-09             35460   \n",
       "2         4  1702169940000   2023-12-10             26220   \n",
       "3         4  1702246860000   2023-12-11             24780   \n",
       "4         4  1702334760000   2023-12-12             23460   \n",
       "5         4  1702421040000   2023-12-13             23760   \n",
       "6         4  1702506960000   2023-12-14             22740   \n",
       "7         4  1702677060000   2023-12-16             37140   \n",
       "8         4  1702772280000   2023-12-17             28920   \n",
       "9         4  1702853220000   2023-12-18             23460   \n",
       "10        4  1703026440000   2023-12-20             23397   \n",
       "11        4  1703112840000   2023-12-21             27180   \n",
       "\n",
       "   sleepStartTimestampLocal sleepEndTimestampLocal  deepSleepSeconds  \\\n",
       "0       2023-12-07 23:34:00    2023-12-08 06:21:00              2640   \n",
       "1       2023-12-08 21:39:00    2023-12-09 09:08:00              4620   \n",
       "2       2023-12-10 01:59:00    2023-12-10 09:29:00              2820   \n",
       "3       2023-12-10 23:21:00    2023-12-11 06:16:00              3420   \n",
       "4       2023-12-11 23:46:00    2023-12-12 06:45:00              5040   \n",
       "5       2023-12-12 23:44:00    2023-12-13 06:30:00              2460   \n",
       "6       2023-12-13 23:36:00    2023-12-14 06:32:00              3120   \n",
       "7       2023-12-15 22:51:00    2023-12-16 09:36:00              7680   \n",
       "8       2023-12-17 01:18:00    2023-12-17 09:40:00              3960   \n",
       "9       2023-12-17 23:47:00    2023-12-18 06:24:00              5940   \n",
       "10      2023-12-19 23:54:00    2023-12-20 06:27:57              3360   \n",
       "11      2023-12-20 23:54:00    2023-12-21 07:33:00              4140   \n",
       "\n",
       "    lightSleepSeconds  remSleepSeconds  awakeSleepSeconds  ...  embedding_99  \\\n",
       "0               16980             3180               1620  ...           0.0   \n",
       "1               23580             7260               5880  ...           0.0   \n",
       "2               18300             5100                780  ...           0.0   \n",
       "3               14520             6840                120  ...           0.0   \n",
       "4               14100             4320               1680  ...           0.0   \n",
       "5               15360             5940                600  ...           0.0   \n",
       "6               14040             5580               2220  ...           0.0   \n",
       "7               17940            11520               1560  ...           0.0   \n",
       "8               19620             5340               1200  ...           0.0   \n",
       "9               14100             3420                360  ...           0.0   \n",
       "10              17040             2940                240  ...           0.0   \n",
       "11              17820             5220                360  ...           0.0   \n",
       "\n",
       "        Datum  ausgeschlafen  motivation  konzentriert Wach  Test_zeit  \\\n",
       "0  2023-12-08              3           3             4    2        NaN   \n",
       "1  2023-12-09              4           1             3    2        NaN   \n",
       "2  2023-12-10              2           2             2    3      60.00   \n",
       "3  2023-12-11              2           3             3    3      61.33   \n",
       "4  2023-12-12              3           3             4    2      60.00   \n",
       "5  2023-12-13              2           2             4    3      63.67   \n",
       "6  2023-12-14              3           3             4    3      51.67   \n",
       "7  2023-12-16              4           3             4    2      51.67   \n",
       "8  2023-12-17              4           5             4    3      55.67   \n",
       "9  2023-12-18              3           3             5    4      61.33   \n",
       "10 2023-12-20              2           4             3    2      68.67   \n",
       "11 2023-12-21              4           4             3    3        NaN   \n",
       "\n",
       "    Test_anzahl  prozent_zeit_rang  prozent_anzahl  \n",
       "0           NaN                NaN             NaN  \n",
       "1           NaN                NaN             NaN  \n",
       "2          93.0                2.0            62.0  \n",
       "3          93.0                3.0            62.0  \n",
       "4          92.0                2.0            56.0  \n",
       "5          97.0                4.0            81.0  \n",
       "6          97.0                0.0            81.0  \n",
       "7          93.0                0.0            62.0  \n",
       "8          99.0                1.0            87.0  \n",
       "9          97.0                3.0            81.0  \n",
       "10         93.0                7.0            62.0  \n",
       "11          NaN                NaN             NaN  \n",
       "\n",
       "[12 rows x 144 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_people_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_id</th>\n",
       "      <th>id</th>\n",
       "      <th>calendarDate</th>\n",
       "      <th>sleepTimeSeconds</th>\n",
       "      <th>sleepStartTimestampLocal</th>\n",
       "      <th>sleepEndTimestampLocal</th>\n",
       "      <th>deepSleepSeconds</th>\n",
       "      <th>lightSleepSeconds</th>\n",
       "      <th>remSleepSeconds</th>\n",
       "      <th>awakeSleepSeconds</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_98</th>\n",
       "      <th>embedding_99</th>\n",
       "      <th>ausgeschlafen</th>\n",
       "      <th>motivation</th>\n",
       "      <th>konzentriert</th>\n",
       "      <th>Wach</th>\n",
       "      <th>Test_zeit</th>\n",
       "      <th>Test_anzahl</th>\n",
       "      <th>prozent_zeit_rang</th>\n",
       "      <th>prozent_anzahl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1701986940000</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>36780</td>\n",
       "      <td>2023-12-07 23:09:00</td>\n",
       "      <td>2023-12-08 09:34:00</td>\n",
       "      <td>3780</td>\n",
       "      <td>27000</td>\n",
       "      <td>6000</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1702078860000</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>29940</td>\n",
       "      <td>2023-12-09 00:41:00</td>\n",
       "      <td>2023-12-09 09:42:00</td>\n",
       "      <td>3240</td>\n",
       "      <td>24480</td>\n",
       "      <td>2220</td>\n",
       "      <td>2520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80.33</td>\n",
       "      <td>71.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1702171920000</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>25080</td>\n",
       "      <td>2023-12-10 02:32:00</td>\n",
       "      <td>2023-12-10 09:39:00</td>\n",
       "      <td>2040</td>\n",
       "      <td>17580</td>\n",
       "      <td>5460</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>79.33</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1702254240000</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>21420</td>\n",
       "      <td>2023-12-11 01:24:00</td>\n",
       "      <td>2023-12-11 07:22:00</td>\n",
       "      <td>3720</td>\n",
       "      <td>15000</td>\n",
       "      <td>2700</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>87.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1702340700000</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>31080</td>\n",
       "      <td>2023-12-12 01:25:00</td>\n",
       "      <td>2023-12-12 10:04:00</td>\n",
       "      <td>6540</td>\n",
       "      <td>17520</td>\n",
       "      <td>7020</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>85.00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1702856640000</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>22620</td>\n",
       "      <td>2023-12-18 00:44:00</td>\n",
       "      <td>2023-12-18 07:11:00</td>\n",
       "      <td>2940</td>\n",
       "      <td>15720</td>\n",
       "      <td>3960</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1702940220000</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>25800</td>\n",
       "      <td>2023-12-18 23:57:00</td>\n",
       "      <td>2023-12-19 07:10:00</td>\n",
       "      <td>2640</td>\n",
       "      <td>15420</td>\n",
       "      <td>7740</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>47.70</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1703028000000</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>26520</td>\n",
       "      <td>2023-12-20 00:20:00</td>\n",
       "      <td>2023-12-20 07:59:00</td>\n",
       "      <td>3420</td>\n",
       "      <td>15120</td>\n",
       "      <td>7980</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44.33</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>1703113800000</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>28320</td>\n",
       "      <td>2023-12-21 00:10:00</td>\n",
       "      <td>2023-12-21 08:07:00</td>\n",
       "      <td>1200</td>\n",
       "      <td>19860</td>\n",
       "      <td>7260</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44.70</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1703201520000</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>27540</td>\n",
       "      <td>2023-12-22 00:32:00</td>\n",
       "      <td>2023-12-22 08:13:00</td>\n",
       "      <td>2100</td>\n",
       "      <td>20040</td>\n",
       "      <td>5400</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>45.67</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp_id             id calendarDate  sleepTimeSeconds  \\\n",
       "0         0  1701986940000   2023-12-08             36780   \n",
       "1         0  1702078860000   2023-12-09             29940   \n",
       "2         0  1702171920000   2023-12-10             25080   \n",
       "3         0  1702254240000   2023-12-11             21420   \n",
       "4         0  1702340700000   2023-12-12             31080   \n",
       "..      ...            ...          ...               ...   \n",
       "5         6  1702856640000   2023-12-18             22620   \n",
       "6         6  1702940220000   2023-12-19             25800   \n",
       "7         6  1703028000000   2023-12-20             26520   \n",
       "8         6  1703113800000   2023-12-21             28320   \n",
       "9         6  1703201520000   2023-12-22             27540   \n",
       "\n",
       "   sleepStartTimestampLocal sleepEndTimestampLocal  deepSleepSeconds  \\\n",
       "0       2023-12-07 23:09:00    2023-12-08 09:34:00              3780   \n",
       "1       2023-12-09 00:41:00    2023-12-09 09:42:00              3240   \n",
       "2       2023-12-10 02:32:00    2023-12-10 09:39:00              2040   \n",
       "3       2023-12-11 01:24:00    2023-12-11 07:22:00              3720   \n",
       "4       2023-12-12 01:25:00    2023-12-12 10:04:00              6540   \n",
       "..                      ...                    ...               ...   \n",
       "5       2023-12-18 00:44:00    2023-12-18 07:11:00              2940   \n",
       "6       2023-12-18 23:57:00    2023-12-19 07:10:00              2640   \n",
       "7       2023-12-20 00:20:00    2023-12-20 07:59:00              3420   \n",
       "8       2023-12-21 00:10:00    2023-12-21 08:07:00              1200   \n",
       "9       2023-12-22 00:32:00    2023-12-22 08:13:00              2100   \n",
       "\n",
       "    lightSleepSeconds  remSleepSeconds  awakeSleepSeconds  ...  embedding_98  \\\n",
       "0               27000             6000                720  ...      0.131409   \n",
       "1               24480             2220               2520  ...      0.350698   \n",
       "2               17580             5460                540  ...      0.000000   \n",
       "3               15000             2700                 60  ...      0.000000   \n",
       "4               17520             7020                 60  ...      0.000000   \n",
       "..                ...              ...                ...  ...           ...   \n",
       "5               15720             3960                600  ...      0.000000   \n",
       "6               15420             7740                180  ...      0.000000   \n",
       "7               15120             7980               1020  ...      0.000000   \n",
       "8               19860             7260                300  ...      0.000000   \n",
       "9               20040             5400                120  ...      0.000000   \n",
       "\n",
       "    embedding_99  ausgeschlafen  motivation  konzentriert Wach  Test_zeit  \\\n",
       "0            0.0              4           3             4    2        NaN   \n",
       "1            0.0              5           5             4    4      80.33   \n",
       "2            0.0              4           2             3    2      79.33   \n",
       "3            0.0              4           4             5    3     100.00   \n",
       "4            0.0              5           5             4    2      85.00   \n",
       "..           ...            ...         ...           ...  ...        ...   \n",
       "5            0.0              3           3             3    3      51.00   \n",
       "6            0.0              3           3             4    3      47.70   \n",
       "7            0.0              4           4             3    3      44.33   \n",
       "8            0.0              5           5             3    3      44.70   \n",
       "9            0.0              4           4             4    3      45.67   \n",
       "\n",
       "    Test_anzahl  prozent_zeit_rang  prozent_anzahl  \n",
       "0           NaN                NaN             NaN  \n",
       "1          71.0               32.0             6.0  \n",
       "2          27.0               33.0             7.0  \n",
       "3          87.0               61.0            28.0  \n",
       "4          81.0               32.0             6.0  \n",
       "..          ...                ...             ...  \n",
       "5          97.0                0.0            81.0  \n",
       "6          93.0                0.0            62.0  \n",
       "7          88.0                0.0            33.0  \n",
       "8          95.0                0.0            72.0  \n",
       "9          93.0                0.0            62.0  \n",
       "\n",
       "[76 rows x 143 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "# combine all data of all people\n",
    "for df in merged_people_data.values():\n",
    "    #print(df.shape)\n",
    "    data = pd.concat([data, df])\n",
    "\n",
    "data.drop('Datum', axis='columns', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76 entries, 0 to 9\n",
      "Columns: 143 entries, temp_id to prozent_anzahl\n",
      "dtypes: datetime64[ns](3), float32(100), float64(18), int64(21), object(1)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2039\n",
       "True        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data without high correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = ['awakeCount', 'lowestRespirationValue', 'highestRespirationValue',\n",
    "                  'sleepScores.remPercentage.idealStartInSeconds', 'sleepScores.remPercentage.idealEndInSeconds', 'sleepScores.lightPercentage.idealStartInSeconds',\n",
    "                  'sleepScores.lightPercentage.idealEndInSeconds', 'sleepScores.deepPercentage.idealStartInSeconds', 'sleepScores.deepPercentage.idealEndInSeconds',\n",
    "                  'sleepScores.remPercentage.value', 'sleepScores.lightPercentage.value', 'sleepScores.deepPercentage.value', \n",
    "                  'sleepVersion', 'remSleepData',\n",
    "                  'sleepScores.totalDuration.value', 'sleepScores.stress.value', 'sleepScores.awakeCount.value', 'sleepScores.restlessness.value']\n",
    "\n",
    "data_filtered = data.drop(cols_to_remove, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size : (57, 113), y_train size : (57,)\n",
      "X_test size : (15, 113), y_test size : (15,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_copy = data_filtered.copy().dropna()\n",
    "\n",
    "# list of columns that need to be dropped\n",
    "to_drop = ['temp_id', 'id', 'calendarDate', 'ageGroup',\n",
    "            'ausgeschlafen', 'motivation', 'Wach', 'konzentriert',\n",
    "            'Test_zeit', 'Test_anzahl','prozent_zeit_rang', 'prozent_anzahl'] \n",
    "\n",
    "# train with the suitable dataset\n",
    "features = data_copy.drop(to_drop, axis=1)  # Drop the target variable to isolate the features\n",
    "target = data_copy['prozent_zeit_rang'].to_numpy()  # Isolate the target variable\n",
    "\n",
    "# Convert Timestamp to Unix format\n",
    "features['sleepStartTimestampLocal'] = features['sleepStartTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "features['sleepEndTimestampLocal'] = features['sleepEndTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train size : {X_train.shape}, y_train size : {y_train.shape}\\nX_test size : {X_test.shape}, y_test size : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ..max_depth=5, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), n_iter=20,\n",
       "                   param_distributions={'max_depth': [5, 8, 10, 12, 15],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "parameters = {\"n_estimators\" : [20, 40, 60, 80],\n",
    "              \"max_depth\": [5, 8, 10, 12, 15],\n",
    "              \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "              \"n_estimators\":[10, 50, 100]}\n",
    " \n",
    "random_search = RandomizedSearchCV(rf_regressor, parameters, n_iter=20, verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 134.93741832857822\n",
      "R-squared: 0.1491727630330092\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "# Train the regressor\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    " \n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.26947685, 13.4105244 , 25.93910965, 24.53630781, 11.37201302,\n",
       "        7.93535895, 23.83188268, 10.50650226,  9.04772489,  6.23208642,\n",
       "       10.88168037, 13.90187742, 10.15563693, 25.23899514, 14.78976551])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.,  5., 37., 32.,  3.,  0.,  7.,  2.,  7.,  0.,  3.,  3., 16.,\n",
       "        0., 33.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=8, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=15, min_samples_leaf=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=15, min_samples_leaf=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=15, min_samples_leaf=8, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=15, min_samples_leaf=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END .max_depth=12, min_samples_leaf=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'max_depth': [5, 8, 10, 12, 15],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_copy = data.copy().dropna()\n",
    "\n",
    "# list of columns that need to be dropped\n",
    "to_drop = ['temp_id', 'id', 'calendarDate', 'ageGroup',\n",
    "            'ausgeschlafen', 'motivation', 'Wach', 'konzentriert',\n",
    "            'Test_zeit', 'Test_anzahl','prozent_zeit_rang', 'prozent_anzahl'] \n",
    "\n",
    "# train with the suitable dataset\n",
    "features = data_copy.drop(to_drop, axis=1)  # Drop the target variable to isolate the features\n",
    "target = pd.get_dummies(data_copy['konzentriert'], dtype=int).to_numpy()  # Isolate the target variable\n",
    "\n",
    "# Convert Timestamp to Unix format\n",
    "features['sleepStartTimestampLocal'] = features['sleepStartTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "features['sleepEndTimestampLocal'] = features['sleepEndTimestampLocal'].astype('int64') // 10**9\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    " \n",
    "# Initialize the Random Forest Regressor\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, criterion='entropy')\n",
    "\n",
    "parameters = {\"n_estimators\" : [20, 40, 60, 80],\n",
    "              \"max_depth\": [5, 8, 10, 12, 15],\n",
    "              \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "              \"n_estimators\":[10, 50, 100]}\n",
    " \n",
    "random_search = RandomizedSearchCV(rf_classifier, parameters, n_iter=20, verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #recall_score, classification_report\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Train the classifier\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print classification report for more detailed performance analysis\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification without one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'max_depth': [5, 8, 10, 12, 15],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_copy = data.copy().dropna()\n",
    "\n",
    "# list of columns that need to be dropped\n",
    "to_drop = ['temp_id', 'id', 'calendarDate', 'ageGroup',\n",
    "            'ausgeschlafen', 'motivation', 'Wach', 'konzentriert',\n",
    "            'Test_zeit', 'Test_anzahl','prozent_zeit_rang', 'prozent_anzahl'] \n",
    "\n",
    "# train with the suitable dataset\n",
    "features = data_copy.drop(to_drop, axis=1)  # Drop the target variable to isolate the features\n",
    "target = data_copy['konzentriert'].to_numpy() # Isolate the target variable\n",
    "\n",
    "# Convert Timestamp to Unix format\n",
    "features['sleepStartTimestampLocal'] = features['sleepStartTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "features['sleepEndTimestampLocal'] = features['sleepEndTimestampLocal'].astype('int64') // 10**9\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    " \n",
    "# Initialize the Random Forest Regressor\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, criterion = 'entropy')\n",
    "\n",
    "parameters = {\"n_estimators\" : [20, 40, 60, 80],\n",
    "              \"max_depth\": [5, 8, 10, 12, 15],\n",
    "              \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "              \"n_estimators\":[10, 50, 100]}\n",
    " \n",
    "random_search = RandomizedSearchCV(rf_classifier, parameters, n_iter=20, verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.00%\n",
      "MSE: 120.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #recall_score, classification_report\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Train the classifier\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 4, 3, 5, 5, 2, 4, 5, 5, 3, 2, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 5, 3, 3, 3, 4, 5, 3, 3, 4, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10572791, 0.48246428, 0.2335502 , 0.17825761],\n",
       "       [0.07224677, 0.3514286 , 0.30375525, 0.27256938],\n",
       "       [0.15071635, 0.49081012, 0.18137878, 0.17709476],\n",
       "       [0.11587354, 0.54590472, 0.14303349, 0.19518824],\n",
       "       [0.04290678, 0.32439333, 0.30033729, 0.3323626 ],\n",
       "       [0.14022909, 0.42521506, 0.23071845, 0.2038374 ],\n",
       "       [0.11765121, 0.3657097 , 0.3229408 , 0.19369828],\n",
       "       [0.1128206 , 0.42118815, 0.3651669 , 0.10082435],\n",
       "       [0.09605275, 0.35285308, 0.37479301, 0.17630116],\n",
       "       [0.08584706, 0.30973843, 0.26744864, 0.33696587],\n",
       "       [0.10403466, 0.45282388, 0.2960403 , 0.14710115],\n",
       "       [0.09941257, 0.45683357, 0.28787027, 0.1558836 ],\n",
       "       [0.03426357, 0.30907925, 0.47761885, 0.17903833],\n",
       "       [0.08640464, 0.41835308, 0.2803419 , 0.21490038],\n",
       "       [0.16844648, 0.35952592, 0.28415913, 0.18786847]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     3\n",
       "0     4\n",
       "5     4\n",
       "1     4\n",
       "3     3\n",
       "1     5\n",
       "11    5\n",
       "9     2\n",
       "13    4\n",
       "5     5\n",
       "9     5\n",
       "6     3\n",
       "10    2\n",
       "7     4\n",
       "6     4\n",
       "Name: konzentriert, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification without One-Hot Encoding - oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size : (57, 113)\n",
      "y_train size : (57,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_copy = data_filtered.copy().dropna()\n",
    "\n",
    "# list of columns that need to be dropped\n",
    "to_drop = ['temp_id', 'id', 'calendarDate', 'ageGroup',\n",
    "            'ausgeschlafen', 'motivation', 'Wach', 'konzentriert',\n",
    "            'Test_zeit', 'Test_anzahl','prozent_zeit_rang', 'prozent_anzahl'] \n",
    "\n",
    "# train with the suitable dataset\n",
    "features = data_copy.drop(to_drop, axis=1)  # Drop the target variable to isolate the features\n",
    "target = data_copy['konzentriert']#.to_numpy() # Isolate the target variable\n",
    "\n",
    "# Convert Timestamp to Unix format\n",
    "features['sleepStartTimestampLocal'] = features['sleepStartTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "features['sleepEndTimestampLocal'] = features['sleepEndTimestampLocal'].astype('int64') // 10**9\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train size : {X_train.shape}\\ny_train size : {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled size : (84, 113)\n",
      "y_train_resampled size : (84,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "# Fit the resampling method to the training data\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"X_train_resampled size : {X_resampled.shape}\\ny_train_resampled size : {y_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33173872,  1.00738623,  1.01218591, ..., -0.41883788,\n",
       "        -0.2652718 ,  0.        ],\n",
       "       [ 0.57144445,  0.26190291,  0.29028154, ..., -0.41883788,\n",
       "        -0.2652718 ,  0.        ],\n",
       "       [ 0.58103268, -1.34526191, -1.3336392 , ..., -0.41883788,\n",
       "        -0.2652718 ,  0.        ],\n",
       "       ...,\n",
       "       [-0.76131943,  1.46666878,  1.45202812, ..., -0.38985427,\n",
       "        -0.2652718 ,  0.        ],\n",
       "       [ 0.09203298, -0.64547995, -0.63277216, ..., -0.41883788,\n",
       "        -0.2652718 ,  0.        ],\n",
       "       [ 1.012503  ,  0.07131847,  0.09463429, ..., -0.41883788,\n",
       "        -0.2652718 ,  0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "konzentriert\n",
       "4    21\n",
       "5    21\n",
       "2    21\n",
       "3    21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=15, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'max_depth': [5, 8, 10, 12, 15],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, criterion = 'entropy')\n",
    "\n",
    "parameters = {\"n_estimators\" : [20, 40, 60, 80],\n",
    "              \"max_depth\": [5, 8, 10, 12, 15],\n",
    "              \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "              \"n_estimators\":[10, 50, 100]}\n",
    " \n",
    "random_search = RandomizedSearchCV(rf_classifier, parameters, n_iter=20, verbose=2)\n",
    "random_search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, min_samples_leaf=6,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, min_samples_leaf=6,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=15, min_samples_leaf=6,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "# Train the regressor\n",
    "best_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.00%\n",
      "MSE: 120.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame([importances], columns=features.columns).T\n",
    "#feature_df.reset_index(inplace=True)\n",
    "feature_df.rename(columns={0: 'importances'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sleepTimeSeconds</th>\n",
       "      <td>0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleepStartTimestampLocal</th>\n",
       "      <td>0.011598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleepEndTimestampLocal</th>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepSleepSeconds</th>\n",
       "      <td>0.007538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightSleepSeconds</th>\n",
       "      <td>0.012918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_95</th>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_96</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_97</th>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_98</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedding_99</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importances\n",
       "sleepTimeSeconds             0.005880\n",
       "sleepStartTimestampLocal     0.011598\n",
       "sleepEndTimestampLocal       0.004063\n",
       "deepSleepSeconds             0.007538\n",
       "lightSleepSeconds            0.012918\n",
       "...                               ...\n",
       "embedding_95                 0.001755\n",
       "embedding_96                 0.000000\n",
       "embedding_97                 0.001155\n",
       "embedding_98                 0.000000\n",
       "embedding_99                 0.000000\n",
       "\n",
       "[113 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in feature_df.index:\n",
    "    if \"embedding\" in row:\n",
    "        feature_df.drop(row,axis='rows', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature_df.sort_values(by=\"importances\",ascending=True).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m names \u001b[38;5;241m=\u001b[39m [features\u001b[38;5;241m.\u001b[39mcolumns[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Ein Barplot erstellen\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerkmalswichtigkeiten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), importances[indices])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "# Die Indizes der Merkmale in absteigender Wichtigkeit sortieren\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Die Namen der sortierten Merkmale\n",
    "names = [features.columns[i] for i in indices]\n",
    "\n",
    "# Ein Barplot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Merkmalswichtigkeiten\")\n",
    "plt.bar(range(features.shape[1]), importances[indices])\n",
    "plt.xticks(range(features.shape[1]), names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification without One-Hot - Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size : (57, 2031)\n",
      "y_train size : (57,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_copy = data.copy().dropna()\n",
    "\n",
    "# list of columns that need to be dropped\n",
    "to_drop = ['temp_id', 'id', 'calendarDate', 'ageGroup',\n",
    "            'ausgeschlafen', 'motivation', 'Wach', 'konzentriert',\n",
    "            'Test_zeit', 'Test_anzahl','prozent_zeit_rang', 'prozent_anzahl'] \n",
    "\n",
    "# train with the suitable dataset\n",
    "features = data_copy.drop(to_drop, axis=1)  # Drop the target variable to isolate the features\n",
    "target = data_copy['konzentriert']#.to_numpy() # Isolate the target variable\n",
    "\n",
    "# Convert Timestamp to Unix format\n",
    "features['sleepStartTimestampLocal'] = features['sleepStartTimestampLocal'].astype('int64') // 10**9\n",
    " \n",
    "features['sleepEndTimestampLocal'] = features['sleepEndTimestampLocal'].astype('int64') // 10**9\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train size : {X_train.shape}\\ny_train size : {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 2.85, 3: 0.6785714285714286, 4: 0.7916666666666666, 5: 1.0961538461538463}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Create a dictionary to map class indices to their respective weights\n",
    "class_weight = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=12, min_samples_leaf=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=15, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=15, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=8, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_leaf=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=8, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END .max_depth=12, min_samples_leaf=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, min_samples_leaf=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=5, min_samples_leaf=2, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(class_weight={2: 2.85,\n",
       "                                                                  3: 0.6785714285714286,\n",
       "                                                                  4: 0.7916666666666666,\n",
       "                                                                  5: 1.0961538461538463},\n",
       "                                                    criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(class_weight={2: 2.85,\n",
       "                                                                  3: 0.6785714285714286,\n",
       "                                                                  4: 0.7916666666666666,\n",
       "                                                                  5: 1.0961538461538463},\n",
       "                                                    criterion=&#x27;entropy&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 8, 10, 12, 15],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={2: 2.85, 3: 0.6785714285714286,\n",
       "                                     4: 0.7916666666666666,\n",
       "                                     5: 1.0961538461538463},\n",
       "                       criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={2: 2.85, 3: 0.6785714285714286,\n",
       "                                     4: 0.7916666666666666,\n",
       "                                     5: 1.0961538461538463},\n",
       "                       criterion=&#x27;entropy&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(class_weight={2: 2.85,\n",
       "                                                                  3: 0.6785714285714286,\n",
       "                                                                  4: 0.7916666666666666,\n",
       "                                                                  5: 1.0961538461538463},\n",
       "                                                    criterion='entropy',\n",
       "                                                    random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'max_depth': [5, 8, 10, 12, 15],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, criterion = 'entropy', class_weight=class_weight)\n",
    "\n",
    "parameters = {\"n_estimators\" : [20, 40, 60, 80],\n",
    "              \"max_depth\": [5, 8, 10, 12, 15],\n",
    "              \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "              \"n_estimators\":[10, 50, 100]}\n",
    " \n",
    "random_search = RandomizedSearchCV(rf_classifier, parameters, n_iter=20, verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={2: 2.85, 3: 0.6785714285714286,\n",
       "                                     4: 0.7916666666666666,\n",
       "                                     5: 1.0961538461538463},\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=6,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={2: 2.85, 3: 0.6785714285714286,\n",
       "                                     4: 0.7916666666666666,\n",
       "                                     5: 1.0961538461538463},\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=6,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={2: 2.85, 3: 0.6785714285714286,\n",
       "                                     4: 0.7916666666666666,\n",
       "                                     5: 1.0961538461538463},\n",
       "                       criterion='entropy', max_depth=10, min_samples_leaf=6,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "# Train the regressor\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.67%\n",
      "MSE: 133.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dig_health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
